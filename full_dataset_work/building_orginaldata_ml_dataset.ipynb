{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "data_path = r'C:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\data\\mal-api-2019\\all_analysis_data.txt'\n",
    "labels_path = r'C:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\data\\mal-api-2019\\labels.txt'\n",
    "\n",
    "# Read the data from all_analysis_data.txt and labels.txt\n",
    "with open(data_path, \"r\") as f:\n",
    "    all_traces = f.read().split('\\n')[:-1]  # Array of all untokenized trace documents\n",
    "\n",
    "with open(labels_path, \"r\") as g:\n",
    "    all_labels = g.read().split('\\n')[:-1]  # Remove last blank newline from list\n",
    "\n",
    "# Define a function to get pairs from a string\n",
    "def get_pairs(s):\n",
    "    words = s.split()\n",
    "    return [words[i] + \" \" + words[i+1] for i in range(len(words) - 1)]\n",
    "\n",
    "# Construct the dataset\n",
    "data = []\n",
    "for i in range(len(all_traces)):\n",
    "    # Get the trace for this id\n",
    "    trace = all_traces[i]\n",
    "\n",
    "    # Get the pairs in this trace\n",
    "    pairs = get_pairs(trace)\n",
    "    pair_freq = Counter(pairs)  # Using Counter to calculate pair frequencies\n",
    "\n",
    "    # Create a row for this trace\n",
    "    row = {\n",
    "        \"trace_id\": i,\n",
    "        \"label\": all_labels[i],  # Get label for trace from all_labels list\n",
    "    }\n",
    "\n",
    "    # Add the pair frequencies to the row\n",
    "    row.update(pair_freq)\n",
    "\n",
    "    # Append this row to the data\n",
    "    data.append(row)\n",
    "\n",
    "# Construct a pandas dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fill NaN values with 0, as these simply represent pairs that were not found in the trace\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "df.to_csv('ml_datasets/dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from collections import Counter\n",
    "# from typing import List, Tuple\n",
    "\n",
    "# data_path = r'C:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\data\\mal-api-2019\\all_analysis_data.txt'\n",
    "# labels_path = r'C:\\Users\\cayde\\Desktop\\Grad_School_stuff\\DataBaseManagement\\Project\\Analysis_Scripts\\data\\mal-api-2019\\labels.txt'\n",
    "\n",
    "# # Read the data from all_analysis_data.txt and labels.txt\n",
    "# with open(data_path, \"r\") as f:\n",
    "#     all_traces = f.read().split('\\n')[:-1]  # Array of all untokenized trace documents\n",
    "\n",
    "# with open(labels_path, \"r\") as g:\n",
    "#     all_labels = g.read().split('\\n')[:-1]  # Remove last blank newline from list\n",
    "\n",
    "# # Define a function to get n-mers from a string\n",
    "# def get_nmers(s: str, n: int) -> Tuple[str]:\n",
    "#     words = s.split()\n",
    "#     return [tuple(words[i:i+n]) for i in range(len(words) - n + 1)]\n",
    "\n",
    "# # Define functions for unimers, dimers and trimers\n",
    "# def get_unimers(s: str) -> Tuple[str]:\n",
    "#     return get_nmers(s, 1)\n",
    "\n",
    "# def get_dimers(s: str) -> Tuple[str]:\n",
    "#     return get_nmers(s, 2)\n",
    "\n",
    "# def get_trimers(s: str) -> Tuple[str]:\n",
    "#     return get_nmers(s, 3)\n",
    "\n",
    "# # Construct the dataset\n",
    "# data = []\n",
    "# for i in range(len(all_traces)):\n",
    "#     # Get the trace for this id\n",
    "#     trace = all_traces[i]\n",
    "\n",
    "#     # Get the unimers, dimers and trimers in this trace\n",
    "#     unimers = get_unimers(trace)\n",
    "#     dimers = get_dimers(trace)\n",
    "#     trimers = get_trimers(trace)\n",
    "\n",
    "#     # Calculate frequencies\n",
    "#     unimer_freq = Counter(unimers)\n",
    "#     dimer_freq = Counter(dimers)\n",
    "#     trimer_freq = Counter(trimers)\n",
    "\n",
    "#     # Create a row for this trace\n",
    "#     row = {\n",
    "#         \"trace_id\": i,\n",
    "#         \"label\": all_labels[i],  # Get label for trace from all_labels list\n",
    "#     }\n",
    "\n",
    "#     # Add the unimer, dimer and trimer frequencies to the row\n",
    "#     row.update(unimer_freq)\n",
    "#     row.update(dimer_freq)\n",
    "#     row.update(trimer_freq)\n",
    "\n",
    "#     # Append this row to the data\n",
    "#     data.append(row)\n",
    "\n",
    "# # Construct a pandas dataframe\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Fill NaN values with 0, as these simply represent pairs that were not found in the trace\n",
    "# df.fillna(0, inplace=True)\n",
    "\n",
    "# # Save the dataframe to a csv file\n",
    "# df.to_csv('ml_datasets/dataset.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
